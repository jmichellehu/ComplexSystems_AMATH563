{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/Users/michellehu/git_dirs/ComplexSystems_AMATH563/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists!\n",
      "Exists!\n",
      "Exists!\n",
      "Exists!\n"
     ]
    }
   ],
   "source": [
    "# Download data if you haven't already\n",
    "gz_fns=[\"t10k-labels-idx1-ubyte.gz\", \n",
    "        \"t10k-images-idx3-ubyte.gz\", \n",
    "        \"train-labels-idx1-ubyte.gz\", \n",
    "        \"train-images-idx3-ubyte.gz\"]\n",
    "data_paths=[data_dir + gz for gz in gz_fns]\n",
    "data_sources=[\"http://yann.lecun.com/exdb/mnist/\" + gz for gz in gz_fns]\n",
    "data_sources\n",
    "for f, source in zip(data_paths, data_sources):\n",
    "    if os.path.exists(f):\n",
    "        print(\"Exists!\")\n",
    "    else:\n",
    "        print(\"Missing\", f)\n",
    "        print(\"Downloading now...\")\n",
    "        !wget -O $f $source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/daniel-e/mnist_octave/blob/master/mnist.py\n",
    "def loadY(fnlabel):\n",
    "    f = gzip.open(fnlabel, 'rb')\n",
    "    f.read(8)\n",
    "    return np.frombuffer(f.read(), dtype = np.uint8)\n",
    "\n",
    "def loadX(fnimg):\n",
    "    f = gzip.open(fnimg, 'rb')\n",
    "    f.read(16)\n",
    "    return np.frombuffer(f.read(), dtype = np.uint8).reshape((-1, 28*28))\n",
    "\n",
    "# Unzip, reformat and reshape\n",
    "trainX = loadX(data_dir+\"train-images-idx3-ubyte.gz\")\n",
    "trainY = loadY(data_dir+\"train-labels-idx1-ubyte.gz\")\n",
    "testX = loadX(data_dir+\"t10k-images-idx3-ubyte.gz\")\n",
    "testY = loadY(data_dir+\"t10k-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(28, 28)\n",
      "28*28 = 784\n",
      "train A: (60000, 784)\n",
      "train B: (60000,)\n",
      "test A: (10000, 784)\n",
      "test B: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# double check that these reshapings make sense\n",
    "print(trainX[0].shape)\n",
    "print(trainX[0].reshape(28,28).shape)\n",
    "print(\"28*28 =\", 28*28)\n",
    "\n",
    "# Check sizes of train and test datasets and labels\n",
    "print(\"train A:\", trainX.shape)\n",
    "print(\"train B:\", trainY.shape)\n",
    "print(\"test A:\", testX.shape)\n",
    "print(\"test B:\", testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits:  0 1 2 3 4 5 6 7 8 9\n",
      "labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Class distribution: [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n"
     ]
    }
   ],
   "source": [
    "# Look at class distribution\n",
    "# http://rasbt.github.io/mlxtend/user_guide/data/loadlocal_mnist/\n",
    "print('Digits:  0 1 2 3 4 5 6 7 8 9')\n",
    "print('labels: %s' % np.unique(trainY))\n",
    "print('Class distribution: %s' % np.bincount(trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out some digits\n",
    "plt.figure(figsize=(16,4))\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(1, 10, i + 1)\n",
    "    img = trainX[i].reshape((28,28))\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# A is the vectorized MNIST training images\n",
    "A=trainX.copy()\n",
    "print(A.shape)\n",
    "\n",
    "# B is the set of output vectors\n",
    "B=trainY.copy()\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using various AX=B solvers, determine a mapping from the image space (A) to the label space (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 µs, sys: 1 µs, total: 30 µs\n",
      "Wall time: 31.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Instantiate logistic regression models\n",
    "\n",
    "# with elasticnet regularization and saga solver\n",
    "saga=LogisticRegression(solver=\"saga\", C=1, n_jobs=4, tol=0.01)\n",
    "saga_elastic_L1=LogisticRegression(solver=\"saga\",  C=0.01, penalty=\"elasticnet\", l1_ratio=1, n_jobs=4, tol=0.01)\n",
    "saga_elastic_L2=LogisticRegression(solver=\"saga\",  C=0.01, penalty=\"elasticnet\", l1_ratio=0, n_jobs=4, tol=0.01)\n",
    "saga_elastic_mix=LogisticRegression(solver=\"saga\",  C=0.01, penalty=\"elasticnet\", l1_ratio=0.8, n_jobs=4, tol=0.01)\n",
    "\n",
    "# with stochastic gradient descent\n",
    "sgd_elastic_L1=LogisticRegression(solver=\"sag\", C=0.01, penalty=\"l1\", n_jobs=4, tol=0.01)\n",
    "sgd_elastic_L2=LogisticRegression(solver=\"sag\", C=0.01, penalty=\"l2\", n_jobs=4, tol=0.01)\n",
    "\n",
    "\n",
    "solvers = [saga,\n",
    "           saga_elastic_L1, \n",
    "           saga_elastic_L2,\n",
    "           saga_elastic_mix,\n",
    "           sgd_elastic_L1,\n",
    "           sgd_elastic_L2\n",
    "          ]\n",
    "\n",
    "sparse_only = [ saga_elastic_L1, \n",
    "               saga_elastic_mix,\n",
    "               sgd_elastic_L1,\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(model, x_train, y_train, x_test, y_test, cv=None):\n",
    "    '''\n",
    "    model = model instance to use with specified solver, regularization etc.\n",
    "    x = samples, features; these are observations (images) with # samples = # measurements and features being the attributes of that measurement\n",
    "    y = samples; these are the _labels_ for the observations of same size as samples\n",
    "    '''\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    score=model.score(x_test, y_test)\n",
    "    \n",
    "    if cv is not None:\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        # Run cv number of simulations using k-fold cross validation approach\n",
    "        cv_scores=cross_val_score(model, x_train, y_train, cv=cv)\n",
    "        return (model, predictions, score, cv_scores)    \n",
    "    else:\n",
    "        return (model, predictions, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model=saga_elastic_L1\n",
    "trained_model, pred, acc = optimize(model, A, B, testX, testY)\n",
    "print(\"model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "saga_elastic_L1_01=LogisticRegression(solver=\"saga\", penalty=\"elasticnet\", l1_ratio=1, n_jobs=4, tol=0.01)\n",
    "model=saga_elastic_L1_01\n",
    "\n",
    "trained_model_01, pred_01, acc_01 = optimize(model, A, B, testX, testY)\n",
    "\n",
    "print(\"model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=trained_model.coef_\n",
    "coef=coef.reshape(10,28,28)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_axis_off()\n",
    "    im = ax.imshow(coef[i], vmin=-0.01, vmax=0.006)\n",
    "    ax.set_title(i)\n",
    "    \n",
    "cb_ax=fig.add_axes([0.92, 0.1, 0.03, 0.8])\n",
    "cbar=fig.colorbar(im, cax=cb_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with no regularization C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=trained_model_01.coef_\n",
    "coef=coef.reshape(10,28,28)\n",
    "cmin=coef.min()\n",
    "cmax=coef.max()\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_axis_off()\n",
    "    im = ax.imshow(coef[i], vmin=cmin, vmax=cmax, cmap=\"RdBu\")\n",
    "    ax.set_title(i)\n",
    "    \n",
    "cb_ax=fig.add_axes([0.92, 0.1, 0.03, 0.8])\n",
    "cbar=fig.colorbar(im, cax=cb_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With strong regularization C=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute losses\n",
    "def compute_loss(model, predictions, testX, testY):\n",
    "    report=metrics.classification_report(testY, predictions)\n",
    "    matrix=metrics.confusion_matrix(testY, predictions, normalize='true')\n",
    "    return (report, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r, m = compute_loss(trained_model, pred, testX, testY)\n",
    "r_01, m_01 = compute_loss(trained_model_01, pred_01, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "sns.heatmap(m, annot=True, fmt=\".0f\", \n",
    "#             linewidths=.5, \n",
    "            square = True, \n",
    "            robust = True,\n",
    "            cmap = 'Blues_r');\n",
    "\n",
    "plt.figure(2)\n",
    "sns.heatmap(m_01, annot=True, fmt=\".0f\", \n",
    "#             linewidths=.5, \n",
    "            square = True, \n",
    "            robust = True,\n",
    "            cmap = 'Blues_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model.n_iter_)\n",
    "print(trained_model_01.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def optimize(model, x_train, y_train, x_test, y_test):\n",
    "    '''\n",
    "    model = model instance to use with specified solver, regularization etc.\n",
    "    x = samples, features; these are observations (images) with # samples = # measurements and features being the attributes of that measurement\n",
    "    y = samples; these are the _labels_ for the observations of same size as samples\n",
    "    '''\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    score=model.score(x_test, y_test)\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    # 5 simulations using k-fold cross validation approach\n",
    "    cv_scores=cross_val_score(model, x_train, y_train, cv=5)\n",
    "    return (model, predictions, score, cv_scores)    \n",
    "\n",
    "model=saga_elastic_L1_01\n",
    "trained_model_01, pred_01, acc_01, cv_01 = optimize(model, A, B, testX, testY)\n",
    "\n",
    "print(\"model trained and cross-validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of cross-validated scores\n",
    "print(\"{0:.3}\".format(np.mean(cv_01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Train, test and assess accuracy of models\n",
    "# trained_models=[]\n",
    "# preds=[]\n",
    "# accs=[]\n",
    "# cvs=[]\n",
    "\n",
    "# for model in solvers:\n",
    "#     trained_model, pred, acc, _ = optimize(model, A, B, testX, testY)\n",
    "#     trained_models.append(trained_model)\n",
    "#     preds.append(pred)\n",
    "#     accs.append(acc)\n",
    "#     cvs.append(cv)\n",
    "#     break\n",
    "# print(\"models trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare bulk accuracies for one simulation\n",
    "solver_names = [\n",
    "           \"saga_elastic_L1\", \n",
    "           \"saga_elastic_L2\",\n",
    "           \"saga_elastic_mix\",\n",
    "           \"sgd_elastic_L1\",\n",
    "           \"sgd_elastic_L2\"\n",
    "          ]\n",
    "\n",
    "bar_positions=range(len(solver_names))\n",
    "plt.bar(x=bar_positions, height=accs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn to plot confusion matrix \n",
    "confusion = metrics.confusion_matrix(testY, predictions)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(confusion, annot=True, fmt=\".0f\", \n",
    "#             linewidths=.5, \n",
    "            square = True, \n",
    "            robust = True,\n",
    "            cmap = 'Blues_r');\n",
    "\n",
    "plt.ylabel('True label');\n",
    "plt.xlabel('Predicted label');\n",
    "\n",
    "# title = str('Accuracy Score: '+ \"{0:.3f}\".format(score))\n",
    "# plt.title(title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promote sparsity and rank which pixels are most informative for digit labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use L1  \n",
    "rank the 784 pixels to see which is most informative  \n",
    "Most informative = largest coefficients in matrix X (trained_model.coef_) --> top 5% of pixels, visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Apply your most important pixels to the test data set to see how accurate you are with as few pixels as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What does this mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Redo the analysis with each digit individually to find the most important pixels for each digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Think about the interpretation of what you are doing with this AX = B problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = something\n",
    "A = trainX (observations)\n",
    "B = trainY (labels)\n",
    "\n",
    "X = beta = loadings so we can transform (i.e. map) A (e.g. data, observations, images) into B (e.g. labels)\n",
    "\n",
    "Determine X using logistic regression specifying solvers, regularization (constraints)\n",
    "Use L1 norm where we minimize the average error (better performance with outliers than L2 norm)\n",
    "\n",
    "Ranking most informative pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gda_py3",
   "language": "python",
   "name": "gda_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
